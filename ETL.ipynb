{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages you may need to import\n",
    "from sklearn.datasets import load_files\n",
    "from scipy.stats import uniform, randint as sp_randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,RandomizedSearchCV, GridSearchCV\n",
    "import nltk\n",
    "from nltk.cluster import KMeansClusterer, cosine_distance\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from nltk import pos_tag\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn import preprocessing, svm\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing on Final Tuk Tuk dataset / Yelp Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuk = pd.read_csv('/Users/MSD/OneDrive - Dartmouth College/182/Final_TukTukThai.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuk_text = tuk[\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords and other characters as defined by me\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "tuk_ready_stem = []\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stem = SnowballStemmer(\"english\")\n",
    "\n",
    "stopw = stopwords.words('english') + list(string.punctuation)  +[\"’\",\"”\",\"—\",\"“\"]\n",
    "\n",
    "\n",
    "for i in range(0,len(tuk_text)):\n",
    "    x = tuk_text[i]\n",
    "    text = re.sub(r'((.)\\2{2,})', ' ', x) #remove three or more consecutive characters like 'trashhhh'\n",
    "    text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "    \n",
    "   \n",
    "    #Words\n",
    "    tokens = [stop for stop in word_tokenize(text.lower()) if stop not in stopw] #removes stopwords, punctuation and custom filter\n",
    "    #tokens = [w for w in tokens if w.isalpha()]  #remove every that is not fully alphabetic\n",
    "    tokens = [w for w in tokens if re.findall(r\"(\\w{3})\",w) ] #removes anything less than 3 characters\n",
    "    tokens = [stem.stem(w) for w in tokens]\n",
    "    review = ' '.join(tokens)\n",
    "    tuk_ready_stem.append(review)\n",
    "    print(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuk_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banker_tuk = []\n",
    "\n",
    "from collections import Counter\n",
    "for i in range(0,len(tuk_ready)):\n",
    "    tokens = [stop for stop in word_tokenize(tuk_ready[i])] #removes stopwords, punctuation and custom filter\n",
    "    post =  pos_tag(tokens)\n",
    "\n",
    "    counts = Counter(tag for word,tag in post)\n",
    "\n",
    "    total = sum(counts.values())\n",
    "    x = dict((word, float(count)/total) for word,count in counts.items())\n",
    "    banker_tuk.append(x)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords and other characters as defined by me\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "polt = []\n",
    "negt = []\n",
    "post = []\n",
    "nuet = []\n",
    "\n",
    "for i in range(0,len(tuk_ready)):\n",
    "    x = tuk_ready[i]\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    polt.append(analyser.polarity_scores(x)['compound'])\n",
    "    negt.append(analyser.polarity_scores(x)['neg'])\n",
    "    post.append(analyser.polarity_scores(x)['pos'])\n",
    "    nuet.append(analyser.polarity_scores(x)['neu'])\n",
    "    print(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(banker_tuk).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuk_pos = pd.DataFrame(banker_tuk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuk_pos.insert(0,\"X.\", 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuk_pos = pd.read_csv('/Users/MSD/OneDrive - Dartmouth College/182/tuk_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuk_pos.fillna(value=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tuk =tuk[[\"sd\", \"numberofwords\",\"numberofsentences\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tuk_1 = pd.concat([final_tuk.reset_index(drop=True), tuk_pos.reset_index(drop=True)], axis=1)\n",
    "#ndf = pd.concat([pos.reset_index(drop=True), rater_ohe.reset_index(drop=True), docs_vectors.reset_index(drop=True),dataset.iloc[:,12].reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tuk_1[\"positive_sent\"] = post\n",
    "final_tuk_1[\"negative_sent\"] = negt\n",
    "final_tuk_1[\"compound_sent\"] = polt\n",
    "final_tuk_1[\"neutral_sent\"] = nuet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tuk_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tuk_2 = pd.get_dummies(final_tuk_1, columns = ['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tuk_3 = final_tuk_2.drop([\"Unnamed: 0\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pd.read_csv('/dartfs-hpc/rc/home/k/f003kdk/ENG182/clean.csv')\n",
    "dataset = pd.read_csv('/Users/MSD/OneDrive - Dartmouth College/182/Final_Dataset_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetstem = pd.read_csv('/Users/MSD/OneDrive - Dartmouth College/182/clean_with_review_stemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"stemmed\"] = datasetstem[\"clean_review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_raw = dataset.iloc[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords and other characters as defined by me\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "text_ready = []\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stem = SnowballStemmer(\"english\")\n",
    "\n",
    "stopw = stopwords.words('english') + list(string.punctuation)  +[\"’\",\"”\",\"—\",\"“\"]\n",
    "\n",
    "\n",
    "for i in range(0,len(text_raw)):\n",
    "    x = text_raw[i]\n",
    "    text = re.sub(r'((.)\\2{2,})', ' ', x) #remove three or more consecutive characters like 'trashhhh'\n",
    "    text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "    \n",
    "   \n",
    "    #Words\n",
    "    tokens = [stop for stop in word_tokenize(text.lower()) if stop not in stopw] #removes stopwords, punctuation and custom filter\n",
    "    #tokens = [w for w in tokens if w.isalpha()]  #remove every that is not fully alphabetic\n",
    "    tokens = [w for w in tokens if re.findall(r\"(\\w{3})\",w) ] #removes anything less than 3 characters\n",
    "    tokens = [stem.stem(w) for w in tokens]\n",
    "    review = ' '.join(tokens)\n",
    "    text_ready.append(review)\n",
    "    print(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"clean_review\"] = pd.DataFrame(text_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"clean_review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords and other characters as defined by me\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "pol = []\n",
    "neg = []\n",
    "pos = []\n",
    "nue = []\n",
    "\n",
    "for i in range(0,len(text_raw)):\n",
    "    x = text_raw[i]\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    pol.append(analyser.polarity_scores(x)['compound'])\n",
    "    neg.append(analyser.polarity_scores(x)['neg'])\n",
    "    pos.append(analyser.polarity_scores(x)['pos'])\n",
    "    nue.append(analyser.polarity_scores(x)['neu'])\n",
    "    print(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"positive_sent\"] = pos\n",
    "dataset[\"negative_sent\"] = neg\n",
    "dataset[\"compound_sent\"] = pol\n",
    "dataset[\"neutral_sent\"] = nue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[:,[54]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rater_ohe = pd.get_dummies(rater, columns = ['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"Final_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = dataset.drop([\"Unnamed: 0\",\"X\", \"Unnamed..0\", \"V1\", \"UserID\", \"ProdID\", \"Date\", \"User\", \"Product\", \"Review\", \"clean_review\", \"Label\", ], axis = 1)\n",
    "df_f2 = pd.get_dummies(df_f, columns = ['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_f = dataset[\"Label\"]\n",
    "y_f2 = y_f.map({1: 1, -1: 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "analyser.polarity_scores(\"I love to gamble my money\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser.polarity_scores(\"Visiting aunts can be a nuisance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('/Users/MSD/OneDrive - Dartmouth College/182/clean_with_review_stemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.drop('Review', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/dartfs-hpc/rc/home/k/f003kdk/ENG182/clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = pd.read_csv('/Users/MSD/OneDrive - Dartmouth College/182/clean.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw1 = dataset.iloc[:,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [stop for stop in word_tokenize(raw1[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw1[754]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banker = []\n",
    "\n",
    "from collections import Counter\n",
    "for i in range(0,len(raw1)):\n",
    "    tokens = [stop for stop in word_tokenize(raw1[i])] #removes stopwords, punctuation and custom filter\n",
    "    post =  pos_tag(tokens)\n",
    "\n",
    "    counts = Counter(tag for word,tag in post)\n",
    "\n",
    "    total = sum(counts.values())\n",
    "    x = dict((word, float(count)/total) for word,count in counts.items())\n",
    "    banker.append(x)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.DataFrame(banker)\n",
    "pos.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.to_csv(\"POS_tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.read_csv('/Users/MSD/OneDrive - Dartmouth College/182/POS_tags.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rater = pd.DataFrame(dataset[\"Rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rater_ohe = pd.get_dummies(rater, columns = ['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_main = pd.concat([pos.reset_index(drop=True), rater_ohe.reset_index(drop=True), pd.DataFrame(dataset.iloc[:,11])], axis=1)\n",
    "#ndf = pd.concat([pos.reset_index(drop=True), rater_ohe.reset_index(drop=True), docs_vectors.reset_index(drop=True),dataset.iloc[:,12].reset_index(drop=True)], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.isnull(ndf).sum()\n",
    "pd.isnull(ndf.dropna()).sum()\n",
    "ndf1 = ndf.dropna()\n",
    "X_main = ndf1.drop([\"Label\"], axis = 1)\n",
    "X_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:,12]\n",
    "\n",
    "#y = ndf1[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text,X_test_text,y_train,y_test=train_test_split(df_f2,\n",
    "                                              y_f2 ,\n",
    "                                                train_size = 0.8,\n",
    "                                               stratify = y_f2,\n",
    "                                              random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df=500,ngram_range=(1,2)).fit(X_train_text[\"stemmed\"])\n",
    "#vect = CountVectorizer(min_df=500,ngram_range=(1,2)).fit(X_train_text[\"stemmed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_vectorized = vect.transform(X_train_text[\"stemmed\"])\n",
    "#X_test_vectorized = vect.transform(X_test_text[\"stemmed\"])\n",
    "tuk_vectorized = vect.transform(tuk_ready_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tuk_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_tuk_dtm = hstack((tuk_vectorized,final_tuk_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tuk_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train_dtm = hstack((X_train_vectorized,X_train_text.drop([\"stemmed\"], axis = 1).values))\n",
    "\n",
    "X_test_dtm = hstack((X_test_vectorized,X_test_text.drop([\"stemmed\"], axis = 1).values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_main = pd.concat([pos.reset_index(drop=True), rater_ohe.reset_index(drop=True), pd.DataFrame(dataset.iloc[:,11])], axis=1)\n",
    "#ndf = pd.concat([pos.reset_index(drop=True), rater_ohe.reset_index(drop=True), docs_vectors.reset_index(drop=True),dataset.iloc[:,12].reset_index(drop=True)], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MaxAbsScaler()\n",
    "X_train_dtm1 = mm.fit_transform(X_train_dtm)\n",
    "X_test_dtm1 = mm.transform(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train_dtm = hstack((X_train_vectorized,X_train_text.drop([\"clean_review\", \"Unnamed: 0\"], axis = 1).values))\n",
    "\n",
    "X_test_dtm = hstack((X_test_vectorized,X_test_text.drop([\"clean_review\", \"Unnamed: 0\"], axis = 1).values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MaxAbsScaler()\n",
    "X_train_dtm1 = mm.fit_transform(X_train_dtm)\n",
    "X_test_dtm1 = mm.transform(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tuk_dtm1 = mm.transform(X_tuk_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nntra = pd.DataFrame(X_train_dtm.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text.drop([ \"Unnamed: 0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = 1) #logistic #Manual Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr.fit(X_train_text.drop([ \"Unnamed: 0\"], axis = 1), y_train1)\n",
    "lr.fit(X_train_dtm1, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = lr.predict(X_test_dtm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tukpreds = lr.predict(X_tuk_dtm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tukpreds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold,StratifiedKFold,RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import uniform, randint as sp_randint\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {  #XGBoost\n",
    "              'XG__objective':['multi:softmax'],\n",
    "              'XG__learning_rate': [0.01,0.02,0.03,0.05,0.07,0.1,0.15], \n",
    "              'XG__max_depth': [6,7,8,10,15],\n",
    "              'XG__min_child_weight': [1,2,3,5,7,11,20],\n",
    "              'XG__silent': [1],\n",
    "              'XG__subsample': [0.8,1,0.5],\n",
    "              'XG__colsample_bytree': [0.7,1,0.5],\n",
    "              'XG__n_estimators': sp_randint(15,2000), \n",
    "              'XG__missing':[-999],\n",
    "              'XG__seed': [1337],\n",
    "             'XG__gamma':[0,5,10,15],\n",
    "             'XG__num_class':[3]} #param grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = RandomizedSearchCV(xg, parameters,n_iter = 200,  \n",
    "                   cv=5, \n",
    "                   scoring='accuracy',\n",
    "                   verbose=2, refit=True, n_jobs = -1)\n",
    "gg.fit(X_train_text.drop([ \"Unnamed: 0\"], axis = 1), y_train1)\n",
    "gg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = XGBClassifier(subsample= 0.8,\n",
    " silent= 1,  \n",
    " seed =1337,\n",
    " objective='binary:logistic',\n",
    " nthread =4,\n",
    " n_estimators =1000,\n",
    " missing= -999,\n",
    " min_child_weight =1,\n",
    " max_depth =7,\n",
    " learning_rate =0.02,\n",
    " gamma =0,\n",
    " colsample_bytree =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  param_grid = {  #random forests\n",
    "    'RF__max_depth': sp_randint(20,80),\n",
    "    'RF__max_features': [\"auto\"],\n",
    "    'RF__min_samples_leaf': sp_randint(1,20),\n",
    "    'RF__min_samples_split': sp_randint(2,20),\n",
    "    'RF__n_estimators': sp_randint(150,500)} #param grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial3 = RandomizedSearchCV(rf,param_distributions = param_grid, n_iter = 400, scoring = \"accuracy\", cv = 10,verbose = 3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial3.fit(X_train_text.drop([ \"Unnamed: 0\"], axis = 1), y_train1) #Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = RandomForestClassifier(n_estimators = 454,\n",
    " max_depth=45,min_samples_leaf = 1, min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4.fit(X_train_text.drop([ \"Unnamed: 0\"], axis = 1), y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgpred = clf4.predict(X_test_text.drop([ \"Unnamed: 0\"], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test1,xgpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential  #Neural Network / CNN / RNN / Word Embeddings 4 different NN models tested\n",
    "from keras.layers import Dense, Embedding, Convolution1D, GlobalMaxPooling1D\n",
    "from keras import layers, models, callbacks, optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    " \n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(1749,)))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(100, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(100, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(50, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', min_delta = 0.0001,patience=6, verbose=0, mode='auto')\n",
    "model.fit(trial, y_train1, epochs=10, validation_split=0.15, batch_size=500,callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Embedding,Conv1D, GlobalMaxPooling1D, LSTM, MaxPooling1D, Bidirectional, Flatten\n",
    "from keras import layers, models, callbacks, optimizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_words = 5000\n",
    "\n",
    "tok = Tokenizer(num_words = max_words)\n",
    "tok.fit_on_texts(X_train_text[\"stemmed\"])\n",
    "tok_train = tok.texts_to_sequences(X_train_text[\"stemmed\"])\n",
    "tok_test = tok.texts_to_sequences(X_test_text[\"stemmed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "tok_train = pad_sequences(tok_train, padding = \"post\", maxlen = maxlen)\n",
    "tok_test= pad_sequences(tok_test, padding = \"post\", maxlen = maxlen)\n",
    "scaler = MinMaxScaler()\n",
    "tok_train1 = scaler.fit_transform(tok_train)\n",
    "tok_test1 = scaler.transform(tok_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_t = pd.DataFrame(X_train_dtm1.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_tes = pd.DataFrame(X_test_dtm1.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=9, padding='same', activation='relu', input_shape=(max(maxlength)+10,512)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(filters=128, kernel_size=7, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Bidirectional(LSTM(50, dropout=0.3, recurrent_dropout=0.2, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(50, dropout=0.25, recurrent_dropout=0.2)))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adpted from kaggle \n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words,100,input_length = 1981))\n",
    "model.add(Conv1D(filters=128, kernel_size=9, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(Conv1D(filters=128, kernel_size=7,  activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(128, activation = 'relu'))\n",
    "#model.add(layers.Dropout(0.25))\n",
    "\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Bidirectional(LSTM(50, dropout=0.3, recurrent_dropout=0.2, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(50, dropout=0.25, recurrent_dropout=0.2)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', min_delta = 0.0001,patience=3, verbose=0, mode='auto')\n",
    "model.fit(nn_t, y_train, epochs=10, validation_split=0.15, batch_size=2000,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R&D / Less than optimal methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect2=CountVectorizer(min_df = 500, ngram_range = (1,2))\n",
    "X_train2 = vect2.fit_transform(X_train_text[\"clean_review\"])\n",
    "X_test2 = vect2.transform(X_test_text[\"clean_review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "lda = LDA(n_topics=100,learning_method = 'batch', max_iter = 30, random_state = 9)\n",
    "lda.fit(X_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = lda.transform(X_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_features = lda.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrs = pd.DataFrame(training_features)\n",
    "xtes = pd.DataFrame(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrs.to_csv(\"LDAuni100_training.csv\")\n",
    "xtes.to_csv(\"LDAuni100_testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LDA_train = pd.concat([xtrs, X_train_text.drop([\"clean_review\", \"Unnamed: 0\"], axis = 1).reset_index(drop=True)], axis=1)\n",
    "X_LDA_test = pd.concat([xtes, X_test_text.drop([\"clean_review\", \"Unnamed: 0\"], axis = 1).reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect3=CountVectorizer(min_df = 100, ngram_range = (2,2))\n",
    "X_train3 = vect3.fit_transform(X_train_text[\"clean_review\"])\n",
    "X_test3 = vect3.transform(X_test_text[\"clean_review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "lda = LDA(n_topics=100,learning_method = 'batch', max_iter = 30, random_state = 9)\n",
    "lda.fit(X_train3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features1 = lda.transform(X_train3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_features1 = lda.transform(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrs1 = pd.DataFrame(training_features1)\n",
    "xtes1 = pd.DataFrame(testing_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrs1.to_csv(\"LDAbi_training.csv\")\n",
    "xtes1.to_csv(\"LDAbi_testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text[[\"Rating_1\",\"Rating_2\",\"Rating_3\",\"Rating_4\",\"Rating_5\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_LDA_train = pd.concat([xtrs, xtrs1 ,pd.DataFrame(X_train_vectorized.toarray()),X_train_text.drop([\"clean_review\", \"Unnamed: 0\"], axis = 1).reset_index(drop=True)], axis=1)\n",
    "#X_LDA_test = pd.concat([xtes,xtes1, pd.DataFrame(X_test_vectorized.toarray()),X_test_text.drop([\"clean_review\", \"Unnamed: 0\"], axis = 1).reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "X_LDA_train = pd.concat([xtrs, xtrs1 ,X_train_text[[\"Rating_1\",\"Rating_2\",\"Rating_3\",\"Rating_4\",\"Rating_5\"]].reset_index(drop=True),pd.DataFrame(X_train_vectorized.toarray())], axis=1)\n",
    "X_LDA_test = pd.concat([xtes,xtes1,X_test_text[[\"Rating_1\",\"Rating_2\",\"Rating_3\",\"Rating_4\",\"Rating_5\"]].reset_index(drop=True),pd.DataFrame(X_test_vectorized.toarray())], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LDA_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LDA_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = [(\"Robust\",MaxAbsScaler()),('SVM',LogisticRegression())]  #Feature Scaling and SVM classifier\n",
    "piped = Pipeline(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piped.fit(X_LDA_train, y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = piped.predict(X_LDA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test1, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LDA_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = pd.DataFrame(X_train_dtm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial1 = pd.DataFrame(X_train_dtm1.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin.gz',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectors = pd.DataFrame() # creating empty final dataframe\n",
    "stopwords = nltk.corpus.stopwords.words('english') # removing stop words\n",
    "for doc in dataset[\"clean_review\"].str.lower().str.replace('[^a-z ]', ''): # looping through each document and cleaning it\n",
    "    temp = pd.DataFrame()  # creating a temporary dataframe(store value for 1st doc & for 2nd doc remove the details of 1st & proced through 2nd and so on..)\n",
    "    for word in doc.split(' '): # looping through each word of a single document and spliting through space\n",
    "         # if word is not present in stopwords then (try)\n",
    "            try:\n",
    "                word_vec = embeddings[word] # if word is present in embeddings(goole provides weights associate with words(300)) then proceed\n",
    "                temp = temp.append(pd.Series(word_vec), ignore_index = True) # if word is present then append it to temporary dataframe\n",
    "            except:\n",
    "                pass\n",
    "    doc_vector = temp.mean() # take the average of each column(w0, w1, w2,........w300)\n",
    "    docs_vectors = docs_vectors.append(doc_vector, ignore_index = True)\n",
    "    # append each document value to the final dataframe\n",
    "    print(doc[0])\n",
    "docs_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectors.to_csv(\"doc2vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(docs_vectors).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
